# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

# Here we set the parts that would
# be re-used between services to an
# extension field
# https://docs.docker.com/compose/compose-file/compose-file-v3/#extension-fields
x-default-isaac-lab-volumes: &default-isaac-lab-volumes
  # These volumes follow from this page
  # https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/install_faq.html#save-isaac-sim-configs-on-local-disk
  - type: volume
    source: isaac-cache-kit
    target: ${DOCKER_ISAACSIM_ROOT_PATH}/kit/cache
  - type: volume
    source: isaac-cache-ov
    target: ${DOCKER_USER_HOME}/.cache/ov
  - type: volume
    source: isaac-cache-pip
    target: ${DOCKER_USER_HOME}/.cache/pip
  - type: volume
    source: isaac-cache-gl
    target: ${DOCKER_USER_HOME}/.cache/nvidia/GLCache
  - type: volume
    source: isaac-cache-compute
    target: ${DOCKER_USER_HOME}/.nv/ComputeCache
  - type: volume
    source: isaac-logs
    target: ${DOCKER_USER_HOME}/.nvidia-omniverse/logs
  - type: volume
    source: isaac-carb-logs
    target: ${DOCKER_ISAACSIM_ROOT_PATH}/kit/logs/Kit/Isaac-Sim
  - type: volume
    source: isaac-data
    target: ${DOCKER_USER_HOME}/.local/share/ov/data
  - type: volume
    source: isaac-docs
    target: ${DOCKER_USER_HOME}/Documents
    # This overlay allows changes on the local files to
    # be reflected within the container immediately
  - type: bind
    source: ../source
    target: ${DOCKER_ISAACLAB_PATH}/source
  - type: bind
    source: ../scripts
    target: ${DOCKER_ISAACLAB_PATH}/scripts
  - type: bind
    source: ../docs
    target: ${DOCKER_ISAACLAB_PATH}/docs
  - type: bind
    source: ../tools
    target: ${DOCKER_ISAACLAB_PATH}/tools
  # Shared playground for all users (host path configurable via HOST_SHARED_DIR, defaults to /srv/isaaclab/shared)
  - type: bind
    source: ${HOST_SHARED_DIR:-/srv/isaaclab/shared}
    target: ${DOCKER_ISAACLAB_PATH}/shared
  # Workspace overlay
  - type: bind
    source: ${HOME}/isaaclab_ws
    target: ${DOCKER_ISAACLAB_PATH}/isaaclab_ws
    # The effect of these volumes is twofold:
    # 1. Prevent root-owned files from flooding the _build and logs dir
    #    on the host machine
    # 2. Preserve the artifacts in persistent volumes for later copying
    #    to the host machine
  - type: volume
    source: isaac-lab-docs
    target: ${DOCKER_ISAACLAB_PATH}/docs/_build
  - type: volume
    source: isaac-lab-logs
    target: ${DOCKER_ISAACLAB_PATH}/logs
  - type: volume
    source: isaac-lab-data
    target: ${DOCKER_ISAACLAB_PATH}/data_storage
    # This volume is used to store the history of the bash shell
  - type: bind
    source: .isaac-lab-docker-history
    target: ${DOCKER_USER_HOME}/.bash_history

x-default-isaac-lab-environment: &default-isaac-lab-environment
  ISAACSIM_PATH: ${DOCKER_ISAACLAB_PATH}/_isaac_sim
  OMNI_KIT_ALLOW_ROOT: "1"
  ISAACLAB_SHARED_DIR: ${DOCKER_ISAACLAB_PATH}/shared

x-default-webrtc-environment: &default-webrtc-environment
  LIVESTREAM: "1"
  ENABLE_CAMERAS: "1"

x-default-isaac-lab-deploy: &default-isaac-lab-deploy
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [ gpu ]

x-default-isaac-lab-base-build: &default-isaac-lab-base-build
  context: ../
  dockerfile: docker/Dockerfile.base
  args:
    - ISAACSIM_BASE_IMAGE_ARG=${ISAACSIM_BASE_IMAGE}
    - ISAACSIM_VERSION_ARG=${ISAACSIM_VERSION}
    - ISAACSIM_ROOT_PATH_ARG=${DOCKER_ISAACSIM_ROOT_PATH}
    - ISAACLAB_PATH_ARG=${DOCKER_ISAACLAB_PATH}
    - DOCKER_USER_HOME_ARG=${DOCKER_USER_HOME}

x-default-isaac-lab-ros2-build: &default-isaac-lab-ros2-build
  context: ../
  dockerfile: docker/Dockerfile.ros2
  args:
    # ROS2_APT_PACKAGE will default to NONE. This is to
    # avoid a warning message when building only the base profile
    # with the .env.base file
    - ROS2_APT_PACKAGE=${ROS2_APT_PACKAGE:-NONE}
    # Make sure that the correct Docker Name Suffix is being passed to the dockerfile, to know which base image to
    # start from.
    - DOCKER_NAME_SUFFIX=${DOCKER_NAME_SUFFIX-}

x-detect-ip-entrypoint: &detect-ip-entrypoint
  - /bin/sh
  - -lc
  - |
    set -u
    term() { printf '[entrypoint] Caught signal, stopping...\n'; exit 0; }
    trap term INT TERM

    ip_cmd() {
      if command -v /sbin/ip >/dev/null 2>&1; then echo /sbin/ip; return; fi
      if command -v ip >/dev/null 2>&1; then echo ip; return; fi
      echo ""
    }

    get_tail_ip() {
      IPCMD="$(ip_cmd)"
      if [ -n "$IPCMD" ]; then
        # exact iface query
        ADDR="$($IPCMD -4 -o addr show dev tailscale0 2>/dev/null | awk '{print $4}' | cut -d/ -f1)" || true
        [ -n "$ADDR" ] && { printf '%s\n' "$ADDR"; return 0; }
      fi
      # fallback: first 100.x from all addrs
      ADDR="$(hostname -I 2>/dev/null | tr ' ' '\n' | awk '/^100\\./{print; exit}')" || true
      [ -n "$ADDR" ] && printf '%s\n' "$ADDR" || return 1
    }

    printf '[entrypoint] Waiting for Tailscale IPv4 on tailscale0…\n'
    backoff=1; cap=10; attempts=0
    PUB=""
    while :; do
      PUB="$(get_tail_ip || true)"
      if [ -n "$PUB" ]; then
        printf '[entrypoint] Found Tailscale IPv4: %s\n' "$PUB"
        break
      fi
      attempts=$((attempts+1))
      printf '[entrypoint] Not ready (attempt %s). Retrying in %ss…\n' "$attempts" "$backoff"
      sleep "$backoff"
      backoff=$(( backoff*2 )); [ "$backoff" -gt "$cap" ] && backoff="$cap"
      if [ $((attempts % 5)) -eq 0 ]; then
        printf '[entrypoint] Debug: ip addr (if available):\n'
        IPCMD="$(ip_cmd)"; [ -n "$IPCMD" ] && $IPCMD -4 addr show 2>/dev/null | sed 's/^/[entrypoint]   /'
        ls -l /sys/class/net/tailscale0 2>/dev/null | sed 's/^/[entrypoint]   /' || true
      fi
    done

    # persist and export
    mkdir -p /run
    printf '%s\n' "$PUB" > /run/public_ip
    export PUBLIC_IP="$PUB"
    : "${LIVESTREAM:=2}"; : "${ENABLE_CAMERAS:=1}"
    printf '[entrypoint] PUBLIC_IP=%s ; LIVESTREAM=%s ; ENABLE_CAMERAS=%s\n' "$PUBLIC_IP" "$LIVESTREAM" "$ENABLE_CAMERAS"

    # make all future shells auto-load it
    cat >/etc/profile.d/public_ip.sh <<'EOF'
    if [ -r /run/public_ip ]; then
      export PUBLIC_IP="$(cat /run/public_ip 2>/dev/null)"
    fi
    EOF
    chmod 644 /etc/profile.d/public_ip.sh
    for rc in /etc/profile /etc/bash.bashrc /root/.bashrc; do
      [ -e "$rc" ] || touch "$rc"
      grep -q 'profile.d/public_ip.sh' "$rc" || echo '. /etc/profile.d/public_ip.sh' >> "$rc"
    done
    if grep -q '^PUBLIC_IP=' /etc/environment 2>/dev/null; then
      sed -i "s|^PUBLIC_IP=.*|PUBLIC_IP=${PUBLIC_IP}|" /etc/environment
    else
      echo "PUBLIC_IP=${PUBLIC_IP}" >> /etc/environment
    fi

x-default-isaac-lab-base: &default-isaac-lab-base
  image: isaac-lab-base${DOCKER_NAME_SUFFIX-}
  container_name: isaac-lab-${SESSION_ID}
  build: *default-isaac-lab-base-build
  volumes: *default-isaac-lab-volumes
  deploy: *default-isaac-lab-deploy
  stdin_open: true
  tty: true

services:
  # This service is the base Isaac Lab image
  isaac-lab-base:
    profiles: [ "base" ]
    env_file: .env.base
    <<: *default-isaac-lab-base
    environment:
      <<: *default-isaac-lab-environment
    network_mode: "host"

  # This service is the base Isaac Lab image with Tailscale networking
  # and WebRTC streaming
  isaac-lab-webrtc:
    profiles: [ "webrtc" ]
    env_file:
      - .env.base
      - .env.tailscale
      - .env.webrtc
    <<: *default-isaac-lab-base
    network_mode: service:tailscale
    depends_on:
      tailscale:
        condition: service_healthy
    entrypoint: *detect-ip-entrypoint
    environment:
      <<: [*default-isaac-lab-environment, *default-webrtc-environment]
    runtime: nvidia
    #ports:
    #  - "${WEBRTC_TCP_PORT}:${WEBRTC_TCP_PORT}/tcp"
    #  - "${WEBRTC_UDP_PORT}:${WEBRTC_UDP_PORT}/udp"
    healthcheck:
      test: ["CMD-SHELL", "ss -lnt 'sport = :49100' | grep -q LISTEN"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 30s

  # This service adds a ROS2 Humble
  # installation on top of the base image
  isaac-lab-ros2:
    profiles: [ "ros2" ]
    env_file:
      - .env.base
      - .env.ros2
    image: isaac-lab-ros2${DOCKER_NAME_SUFFIX-}
    container_name: isaac-lab-ros2${DOCKER_NAME_SUFFIX-}
    build: *default-isaac-lab-ros2-build
    environment: *default-isaac-lab-environment
    volumes: *default-isaac-lab-volumes
    deploy: *default-isaac-lab-deploy
    network_mode: host
    # This is the entrypoint for the container
    entrypoint: bash
    stdin_open: true
    tty: true

volumes:
  # isaac-sim
  isaac-cache-kit:
  isaac-cache-ov:
  isaac-cache-pip:
  isaac-cache-gl:
  isaac-cache-compute:
  isaac-logs:
  isaac-carb-logs:
  isaac-data:
  isaac-docs:
  # isaac-lab
  isaac-lab-docs:
  isaac-lab-logs:
  isaac-lab-data:
